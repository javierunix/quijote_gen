This repository contain some exercise about text generation using Keras.

The code has been implemented according the instructions of the page 
http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/
The only differences is that I am using "El Quijote" instead of "Alice in Wonderland".
Obviously, being a much larger, book will result in a much longer training time. 
On the other hand I am using python 3.5 instead of python 2.7 (that is the version used) in the original file.
If you do not have an Nvidia GPU to make the training faster, I strongly recommend you to use an AWS with this capability, such as vict0rsch-1.0 on North California, the one I am using.
You can find the instructions here: http://vict0rsch.github.io/2016/12/03/aws_gpu/
Traing such a big model using just CPU will take you forever.
